{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing - Evaluation metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow/Keras library - Deep Learning models\n",
    "import tensorflow\n",
    "from keras.layers import SimpleRNN, LSTM, Conv1D, MaxPooling1D, Flatten, Concatenate, Dense\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import Input, Model, Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seed libraries\n",
    "import os\n",
    "import random\n",
    "from tensorflow.random import set_seed\n",
    "from keras.utils import set_random_seed\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed value to 42\n",
    "seed_value= 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "session_conf = tensorflow.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tensorflow.compat.v1.Session(graph=tensorflow.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data\n",
    "data = pd.read_excel('default of credit card clients.xls',header=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for initial preprocessing of the data:\n",
    "1) replace EDUCATION values 0, 5, 6 with 4 ('other' category) since they are not mentioned in the data description\n",
    "2) replace MARRIAGE value 0 with 3 ('other' category) as there is not a 0 category for marriage column on data description \n",
    "3) drop 'ID' column - useless\n",
    "4) rename target column to DEFAULT, rename PAY_0 to PAY_1 for consistency and more accurate variable names\n",
    "'''\n",
    "def initial_preprocessing(df):\n",
    "    print('EDUCATION values before preprocessing:\\n',df['EDUCATION'].value_counts())\n",
    "    df['EDUCATION'].replace([0,5,6],4,inplace=True)\n",
    "    print()\n",
    "    print('EDUCATION values after preprocessing:\\n',df['EDUCATION'].value_counts())\n",
    "    print()\n",
    "    print('MARRIAGE values before preprocessing:\\n',df['MARRIAGE'].value_counts())\n",
    "    df['MARRIAGE'].replace(0,3,inplace=True)\n",
    "    print()\n",
    "    print('MARRIAGE values after preprocessing:\\n',df['MARRIAGE'].value_counts())\n",
    "    df.drop(columns='ID',inplace=True)\n",
    "    df.rename(columns={\"default payment next month\": \"DEFAULT\",\"PAY_0\": \"PAY_1\"},inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION values before preprocessing:\n",
      " 2    14030\n",
      "1    10585\n",
      "3     4917\n",
      "5      280\n",
      "4      123\n",
      "6       51\n",
      "0       14\n",
      "Name: EDUCATION, dtype: int64\n",
      "\n",
      "EDUCATION values after preprocessing:\n",
      " 2    14030\n",
      "1    10585\n",
      "3     4917\n",
      "4      468\n",
      "Name: EDUCATION, dtype: int64\n",
      "\n",
      "MARRIAGE values before preprocessing:\n",
      " 2    15964\n",
      "1    13659\n",
      "3      323\n",
      "0       54\n",
      "Name: MARRIAGE, dtype: int64\n",
      "\n",
      "MARRIAGE values after preprocessing:\n",
      " 2    15964\n",
      "1    13659\n",
      "3      377\n",
      "Name: MARRIAGE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#perform initial preprocessing\n",
    "data = initial_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24000, 23)\n",
      "X_test shape: (6000, 23)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- train test split (20% test) before scaling and encoding to prevent data leakages \n",
    "- train set will be used for cross-validation/hyperparameter tuning and test set for final evaluation \n",
    "- Stratify is used to ensure that the proportion of the class labels will remain consistent\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('DEFAULT',axis=1),data['DEFAULT'],\n",
    "                                                    test_size=0.2,stratify=data['DEFAULT'],random_state=42)\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column transformer for Robust Scaler and One Hot Encoder \n",
    "## making sure to return the preprocessed dataframes for better inspection\n",
    "\n",
    "class PreprocessorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns,columns_num, drop='first', handle_unknown='ignore',sparse_output=False):\n",
    "        self.columns = columns\n",
    "        self.columns_num = columns_num\n",
    "        self.drop = drop\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.sparse_output = sparse_output\n",
    "        self.encoders = {}\n",
    "        self.robust_enc = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            encoder = OneHotEncoder(drop=self.drop, sparse_output=self.sparse_output, \n",
    "                                    handle_unknown=self.handle_unknown)\n",
    "            encoder.fit(X[[col]])\n",
    "            self.encoders[col] = encoder\n",
    "        \n",
    "        for col_num in self.columns_num:\n",
    "            encoder_robust = RobustScaler()\n",
    "            encoder_robust.fit(X[[col_num]])\n",
    "            self.robust_enc[col_num] = encoder_robust\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            encoder = self.encoders[col]\n",
    "            encoded_cols = encoder.transform(transformed[[col]])\n",
    "            new_cols = [f\"{col}_{value}\" for value in encoder.categories_[0][1:]]\n",
    "            encoded_cols_df = pd.DataFrame(encoded_cols, columns=new_cols, index=transformed.index)\n",
    "            transformed = pd.concat([transformed, encoded_cols_df], axis=1)\n",
    "        transformed = transformed.drop(self.columns, axis=1)\n",
    "        \n",
    "        for col_num in self.columns_num:\n",
    "            encoder_robust = self.robust_enc[col_num]\n",
    "            transformed[col_num] = encoder_robust.transform(transformed[[col_num]])\n",
    "            \n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    cat_cols = ['EDUCATION','MARRIAGE']\n",
    "    numerical_cols = ['LIMIT_BAL', 'AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5',\n",
    "                  'BILL_AMT6','PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "    \n",
    "    temp_cols = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
    "    'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
    "    'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "    'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "    \n",
    "    PAY_cols = ['PAY_6', 'PAY_5', 'PAY_4', 'PAY_3', 'PAY_2','PAY_1']\n",
    "    BILL_AMT_cols = ['BILL_AMT6','BILL_AMT5','BILL_AMT4','BILL_AMT3','BILL_AMT2','BILL_AMT1']\n",
    "    PAY_AMT_cols = ['PAY_AMT6','PAY_AMT5', 'PAY_AMT4', 'PAY_AMT3', 'PAY_AMT2', 'PAY_AMT1']\n",
    "    \n",
    "    #fitting the column transformer\n",
    "    enc = PreprocessorTransformer(columns = cat_cols, columns_num= numerical_cols,\n",
    "                                  drop='first',handle_unknown='ignore',sparse_output=False) \n",
    "    \n",
    "    X_train_preprocessed = enc.fit_transform(X_train)\n",
    "    X_test_preprocessed = enc.transform(X_test)\n",
    "    \n",
    "    static_cols_train = X_train_preprocessed.drop(temp_cols,axis=1).columns.to_list()\n",
    "    static_cols_test = X_test_preprocessed.drop(temp_cols,axis=1).columns.to_list()\n",
    "    \n",
    "    #separation of static and temporal features\n",
    "    X_train_temp = X_train_preprocessed[temp_cols]\n",
    "    X_train_static = X_train_preprocessed[static_cols_train]\n",
    "    X_test_temp = X_test_preprocessed[temp_cols]\n",
    "    X_test_static = X_test_preprocessed[static_cols_test]\n",
    "\n",
    "    PAY_train = X_train_temp[PAY_cols].to_numpy()\n",
    "    BILL_AMT_train = X_train_temp[BILL_AMT_cols].to_numpy()\n",
    "    PAY_AMT_train = X_train_temp[PAY_AMT_cols].to_numpy()\n",
    "    \n",
    "    PAY_test = X_test_temp[PAY_cols].to_numpy()\n",
    "    BILL_AMT_test = X_test_temp[BILL_AMT_cols].to_numpy()\n",
    "    PAY_AMT_test = X_test_temp[PAY_AMT_cols].to_numpy()   \n",
    "    \n",
    "    # Stacking temporal features\n",
    "    stacked_train = np.dstack((PAY_train, BILL_AMT_train, PAY_AMT_train))\n",
    "    stacked_test = np.dstack((PAY_test, BILL_AMT_test, PAY_AMT_test))\n",
    "    y_train_preprocessed = y_train.to_numpy()\n",
    "    y_test_preprocessed = y_test.to_numpy()\n",
    "    \n",
    "    return stacked_train, X_train_static, y_train_preprocessed, stacked_test, X_test_static, y_test_preprocessed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temporal, X_train_static, y_train_preprocessed, X_test_temporal,\\\n",
    "X_test_static, y_test_preprocessed = preprocess_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps, num_features = X_train_temporal.shape[1], X_train_temporal.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized temporal models (Dense layer)\n",
    "\n",
    "def RNN_Temporal():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32,return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(SimpleRNN(32,return_sequences = True))\n",
    "    model.add(SimpleRNN(32,return_sequences = True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def LSTM_Temporal():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def CNN_Temporal():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, padding='same', activation='relu',\n",
    "                     input_shape=(num_time_steps, num_features)))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized temporal models (with ML in FCL)\n",
    "\n",
    "def RNN_Temporal_LR():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def LSTM_Temporal_LR():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def CNN_Temporal_LR():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, padding='same', activation='relu', \n",
    "                     input_shape=(num_time_steps, num_features)))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def RNN_Temporal_RF():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def LSTM_Temporal_RF():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def CNN_Temporal_RF():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=8, kernel_size=5, padding='same', activation='relu',\n",
    "                     input_shape=(num_time_steps, num_features)))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def RNN_Temporal_XGB():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(16, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def LSTM_Temporal_XGB():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, return_sequences=True, input_shape=(num_time_steps, num_features)))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def CNN_Temporal_XGB():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, padding='same', activation='relu', \n",
    "                     input_shape=(num_time_steps, num_features)))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten(name='FLATTEN'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training and evaluating on test set for optimized configurations (temporal - dense)\n",
    "\n",
    "def temporal_dense_evaluation(X_train, y_train, X_test, y_test, batch_size, optimizer, \n",
    "                              initial_learning_rate, model):\n",
    "    \n",
    "    decay_rate = 0.1  # Decay rate\n",
    "    decay_steps = 20  # Decay steps (number of steps before applying decay)\n",
    "    epochs = 50\n",
    "\n",
    "    def learning_rate_scheduler(epoch):\n",
    "        return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "    \n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=initial_learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test), shuffle=False, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Plot the loss on train vs validate tests\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate on the testing set\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    test_accuracy =  accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 =  f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    y_train_pred_probs = model.predict(X_train)\n",
    "    y_train_pred = (y_train_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "   \n",
    "    print(f\"Testing Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % test_accuracy)\n",
    "    print(\"Precision: %.3f\" % test_precision)\n",
    "    print(\"Recall: %.3f\" % test_recall)\n",
    "    print(\"F1 score: %.3f\" % test_f1)\n",
    "  \n",
    "    print('-----------------------------------')\n",
    "    print(f\"Training Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % train_accuracy)\n",
    "    print(\"Precision: %.3f\" % train_precision)\n",
    "    print(\"Recall: %.3f\" % train_recall)\n",
    "    print(\"F1 score: %.3f\" % train_f1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training and evaluating on test set for optimized configurations (temporal - ML)\n",
    "\n",
    "def temporal_ML_evaluation(X_train, y_train, X_test, y_test, batch_size, optimizer, \n",
    "                           initial_learning_rate, model, ml_model):\n",
    "    \n",
    "    decay_rate = 0.1  # Decay rate\n",
    "    decay_steps = 20  # Decay steps (number of steps before applying decay)\n",
    "    epochs = 50\n",
    "\n",
    "    def learning_rate_scheduler(epoch):\n",
    "        return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "    \n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=initial_learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(X_test, y_test), shuffle=False, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Plot the loss on train vs validate tests\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    preds,preds_train = classifier_prediction_temporal(X_train,X_test, y_train, \n",
    "                                                       model = ml_model, feature_extractor_model= model, \n",
    "                                                       layer_name='FLATTEN')\n",
    "    \n",
    "    \n",
    "    # Evaluate on the testing set\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "    test_precision = precision_score(y_test, preds)\n",
    "    test_recall = recall_score(y_test, preds)\n",
    "    test_f1 = f1_score(y_test, preds)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    train_precision = precision_score(y_train, preds_train)\n",
    "    train_recall = recall_score(y_train, preds_train)\n",
    "    train_f1 = f1_score(y_train, preds_train)\n",
    "   \n",
    "    print(f\"Testing Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % test_accuracy)\n",
    "    print(\"Precision: %.3f\" % test_precision)\n",
    "    print(\"Recall: %.3f\" % test_recall)\n",
    "    print(\"F1 score: %.3f\" % test_f1)\n",
    "  \n",
    "    print('-----------------------------------')\n",
    "    print(f\"Training Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % train_accuracy)\n",
    "    print(\"Precision: %.3f\" % train_precision)\n",
    "    print(\"Recall: %.3f\" % train_recall)\n",
    "    print(\"F1 score: %.3f\" % train_f1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Temporal (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 0.4906 - accuracy: 0.7809 - val_loss: 0.4631 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4547 - accuracy: 0.8040 - val_loss: 0.4538 - val_accuracy: 0.8037 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.4479 - accuracy: 0.8074 - val_loss: 0.4497 - val_accuracy: 0.8068 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4443 - accuracy: 0.8095 - val_loss: 0.4474 - val_accuracy: 0.8082 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4419 - accuracy: 0.8117 - val_loss: 0.4457 - val_accuracy: 0.8083 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4401 - accuracy: 0.8129 - val_loss: 0.4444 - val_accuracy: 0.8108 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4387 - accuracy: 0.8139 - val_loss: 0.4434 - val_accuracy: 0.8132 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4375 - accuracy: 0.8152 - val_loss: 0.4427 - val_accuracy: 0.8138 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4365 - accuracy: 0.8163 - val_loss: 0.4421 - val_accuracy: 0.8157 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4357 - accuracy: 0.8170 - val_loss: 0.4415 - val_accuracy: 0.8163 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4350 - accuracy: 0.8179 - val_loss: 0.4411 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4344 - accuracy: 0.8185 - val_loss: 0.4407 - val_accuracy: 0.8168 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4338 - accuracy: 0.8185 - val_loss: 0.4403 - val_accuracy: 0.8175 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4333 - accuracy: 0.8189 - val_loss: 0.4400 - val_accuracy: 0.8177 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4328 - accuracy: 0.8193 - val_loss: 0.4398 - val_accuracy: 0.8180 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4323 - accuracy: 0.8194 - val_loss: 0.4395 - val_accuracy: 0.8173 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4319 - accuracy: 0.8195 - val_loss: 0.4393 - val_accuracy: 0.8173 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4315 - accuracy: 0.8197 - val_loss: 0.4391 - val_accuracy: 0.8173 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4312 - accuracy: 0.8201 - val_loss: 0.4389 - val_accuracy: 0.8172 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4308 - accuracy: 0.8202 - val_loss: 0.4388 - val_accuracy: 0.8173 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4294 - accuracy: 0.8213 - val_loss: 0.4384 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4293 - accuracy: 0.8214 - val_loss: 0.4384 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4292 - accuracy: 0.8213 - val_loss: 0.4384 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4291 - accuracy: 0.8213 - val_loss: 0.4384 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4291 - accuracy: 0.8213 - val_loss: 0.4384 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4291 - accuracy: 0.8215 - val_loss: 0.4384 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4290 - accuracy: 0.8215 - val_loss: 0.4384 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4290 - accuracy: 0.8215 - val_loss: 0.4384 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4290 - accuracy: 0.8216 - val_loss: 0.4383 - val_accuracy: 0.8168 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4289 - accuracy: 0.8216 - val_loss: 0.4383 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4289 - accuracy: 0.8216 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.4288 - accuracy: 0.8215 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4288 - accuracy: 0.8215 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.4288 - accuracy: 0.8215 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.4287 - accuracy: 0.8217 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.4287 - accuracy: 0.8217 - val_loss: 0.4383 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.4287 - accuracy: 0.8217 - val_loss: 0.4382 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4286 - accuracy: 0.8217 - val_loss: 0.4382 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.4286 - accuracy: 0.8217 - val_loss: 0.4382 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4286 - accuracy: 0.8217 - val_loss: 0.4382 - val_accuracy: 0.8165 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4284 - accuracy: 0.8220 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.4284 - accuracy: 0.8220 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.4283 - accuracy: 0.8218 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8220 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8220 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8220 - val_loss: 0.4382 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8220 - val_loss: 0.4381 - val_accuracy: 0.8163 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8219 - val_loss: 0.4381 - val_accuracy: 0.8162 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8219 - val_loss: 0.4381 - val_accuracy: 0.8162 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4283 - accuracy: 0.8219 - val_loss: 0.4381 - val_accuracy: 0.8160 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "Testing Set Performance\n",
      "Accuracy: 0.816\n",
      "Precision: 0.653\n",
      "Recall: 0.359\n",
      "F1 score: 0.464\n",
      "-----------------------------------\n",
      "Training Set Performance\n",
      "Accuracy: 0.822\n",
      "Precision: 0.675\n",
      "Recall: 0.377\n",
      "F1 score: 0.484\n"
     ]
    }
   ],
   "source": [
    "temporal_dense_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=32,\n",
    "                          optimizer='rmsprop',initial_learning_rate=0.0001, model=RNN_Temporal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Temporal (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_dense_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                          optimizer='adam',initial_learning_rate=0.0001, model=LSTM_Temporal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Temporal (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_dense_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                          optimizer='adam',initial_learning_rate=0.001, model=CNN_Temporal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Temporal + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=128,\n",
    "                       optimizer='rmsprop',initial_learning_rate=0.0001, \n",
    "                       model=RNN_Temporal_LR(),ml_model = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='adam',initial_learning_rate=0.001, \n",
    "                       model=RNN_Temporal_RF(),ml_model = RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='adam',initial_learning_rate=0.0001, \n",
    "                       model=RNN_Temporal_XGB(),ml_model = XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Temporal + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=32,\n",
    "                       optimizer='adam',initial_learning_rate=0.0001, \n",
    "                       model=LSTM_Temporal_LR(),ml_model = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='rmsprop',initial_learning_rate=0.001,\n",
    "                       model=LSTM_Temporal_RF(),ml_model = RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=32,\n",
    "                       optimizer='rmsprop',initial_learning_rate=0.0001, \n",
    "                       model=LSTM_Temporal_XGB(),ml_model = XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Temporal + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='adam',initial_learning_rate=0.001, \n",
    "                       model=CNN_Temporal_LR(),ml_model = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='adam',initial_learning_rate=0.001, \n",
    "                       model=CNN_Temporal_RF(),ml_model = RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_ML_evaluation(X_train_temporal, y_train_preprocessed,X_test_temporal, y_test_preprocessed,batch_size=64,\n",
    "                       optimizer='adam',initial_learning_rate=0.001, \n",
    "                       model=CNN_Temporal_XGB(),ml_model = XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static + Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Concat models (Dense layer)\n",
    "\n",
    "def RNN_Concat():\n",
    "    rnn_layer = SimpleRNN(64,return_sequences=True, name = 'RNN_LAYER_1')(temporal_input)\n",
    "    rnn_layer = SimpleRNN(64,return_sequences=True, name = 'RNN_LAYER_2')(rnn_layer)\n",
    "    rnn_layer = SimpleRNN(64,return_sequences=True, name = 'RNN_LAYER_3')(rnn_layer)\n",
    "    rnn_layer = Flatten(name = 'FLATTEN')(rnn_layer)\n",
    "    RNN_combined = Concatenate(axis=1, name ='RNN_CONCAT')([rnn_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='RNN_OUTPUT_LAYER')(RNN_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def LSTM_Concat():\n",
    "    lstm_layer = LSTM(64,return_sequences=True, name = 'LSTM_LAYER_1')(temporal_input)\n",
    "    lstm_layer = LSTM(64,return_sequences=True, name = 'LSTM_LAYER_2')(lstm_layer)\n",
    "    lstm_layer = LSTM(64,return_sequences=True, name = 'LSTM_LAYER_3')(lstm_layer)\n",
    "    lstm_layer = LSTM(64,return_sequences=True, name = 'LSTM_LAYER_4')(lstm_layer)\n",
    "    lstm_layer = Flatten(name = 'FLATTEN')(lstm_layer)\n",
    "    LSTM_combined = Concatenate(axis=1, name ='LSTM_CONCAT')([lstm_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='LSTM_OUTPUT_LAYER')(LSTM_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def CNN_Concat():\n",
    "    cnn_layer = Conv1D(filters=256, kernel_size=5, activation='relu',padding='same', name=f'CNN_LAYER_1')(temporal_input)\n",
    "    cnn_layer = MaxPooling1D(pool_size=3)(cnn_layer)\n",
    "    cnn_layer = Flatten(name='FLATTEN')(cnn_layer)\n",
    "    CNN_combined = Concatenate(axis=1, name='cnn_CONCAT')([cnn_layer, static_input])\n",
    "    output = Dense(1, activation='sigmoid', name='cnn_OUTPUT_LAYER')(CNN_combined)\n",
    "    model = Model(inputs=[temporal_input, static_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Concat models (with ML in FCL)\n",
    "\n",
    "def RNN_Concat_LR():\n",
    "    rnn_layer = SimpleRNN(32,return_sequences=True, name = 'RNN_LAYER_1')(temporal_input)\n",
    "    rnn_layer = SimpleRNN(32,return_sequences=True, name = 'RNN_LAYER_2')(rnn_layer)\n",
    "    rnn_layer = Flatten(name = 'FLATTEN')(rnn_layer)\n",
    "    RNN_combined = Concatenate(axis=1, name ='CONCAT')([rnn_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='RNN_OUTPUT_LAYER')(RNN_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def LSTM_Concat_LR():\n",
    "    lstm_layer = LSTM(32,return_sequences=True, name = 'LSTM_LAYER_1')(temporal_input)\n",
    "    lstm_layer = LSTM(32,return_sequences=True, name = 'LSTM_LAYER_2')(lstm_layer)\n",
    "    lstm_layer = Flatten(name = 'FLATTEN')(lstm_layer)\n",
    "    LSTM_combined = Concatenate(axis=1, name ='CONCAT')([lstm_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='LSTM_OUTPUT_LAYER')(LSTM_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def CNN_Concat_LR():\n",
    "    cnn_layer = Conv1D(filters=4, kernel_size=5, activation='relu',padding='same', name=f'CNN_LAYER_1')(temporal_input)\n",
    "    cnn_layer = MaxPooling1D(pool_size=3)(cnn_layer)\n",
    "    cnn_layer = Conv1D(filters=8, kernel_size=3, activation='relu',padding='same', name=f'CNN_LAYER_2')(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "    cnn_layer = Flatten(name='FLATTEN')(cnn_layer)\n",
    "    CNN_combined = Concatenate(axis=1, name='CONCAT')([cnn_layer, static_input])\n",
    "    output = Dense(1, activation='sigmoid', name='cnn_OUTPUT_LAYER')(CNN_combined)\n",
    "    model = Model(inputs=[temporal_input, static_input], outputs=[output])\n",
    "    return model\n",
    "\n",
    "def RNN_Concat_RF():\n",
    "    rnn_layer = SimpleRNN(16,return_sequences=True, name = 'RNN_LAYER_1')(temporal_input)\n",
    "    rnn_layer = Flatten(name = 'FLATTEN')(rnn_layer)\n",
    "    RNN_combined = Concatenate(axis=1, name ='CONCAT')([rnn_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='RNN_OUTPUT_LAYER')(RNN_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def LSTM_Concat_RF():\n",
    "    lstm_layer = LSTM(16,return_sequences=True, name = 'LSTM_LAYER_1')(temporal_input)\n",
    "    lstm_layer = Flatten(name = 'FLATTEN')(lstm_layer)\n",
    "    LSTM_combined = Concatenate(axis=1, name ='CONCAT')([lstm_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='LSTM_OUTPUT_LAYER')(LSTM_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def CNN_Concat_RF():\n",
    "    cnn_layer = Conv1D(filters=8, kernel_size=5, activation='relu',padding='same', name=f'CNN_LAYER_1')(temporal_input)\n",
    "    cnn_layer = MaxPooling1D(pool_size=3)(cnn_layer)\n",
    "    cnn_layer = Conv1D(filters=16, kernel_size=3, activation='relu',padding='same', name=f'CNN_LAYER_2')(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "    cnn_layer = Flatten(name='FLATTEN')(cnn_layer)\n",
    "    CNN_combined = Concatenate(axis=1, name='CONCAT')([cnn_layer, static_input])\n",
    "    output = Dense(1, activation='sigmoid', name='cnn_OUTPUT_LAYER')(CNN_combined)\n",
    "    model = Model(inputs=[temporal_input, static_input], outputs=[output])\n",
    "    return model\n",
    "\n",
    "def RNN_Concat_XGB():\n",
    "    rnn_layer = SimpleRNN(128,return_sequences=True, name = 'RNN_LAYER_1')(temporal_input)\n",
    "    rnn_layer = SimpleRNN(128,return_sequences=True, name = 'RNN_LAYER_2')(rnn_layer)\n",
    "    rnn_layer = Flatten(name = 'FLATTEN')(rnn_layer)\n",
    "    RNN_combined = Concatenate(axis=1, name ='CONCAT')([rnn_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='RNN_OUTPUT_LAYER')(RNN_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def LSTM_Concat_XGB():\n",
    "    lstm_layer = LSTM(32,return_sequences=True, name = 'LSTM_LAYER_1')(temporal_input)\n",
    "    lstm_layer = LSTM(32,return_sequences=True, name = 'LSTM_LAYER_2')(lstm_layer)\n",
    "    lstm_layer = LSTM(32,return_sequences=True, name = 'LSTM_LAYER_3')(lstm_layer)\n",
    "    lstm_layer = Flatten(name = 'FLATTEN')(lstm_layer)\n",
    "    LSTM_combined = Concatenate(axis=1, name ='CONCAT')([lstm_layer,static_input])\n",
    "    output = Dense(1,activation='sigmoid',name='LSTM_OUTPUT_LAYER')(LSTM_combined)\n",
    "    model = Model(inputs=[temporal_input,static_input],outputs=[output])\n",
    "    return model\n",
    "\n",
    "def CNN_Concat_XGB():\n",
    "    cnn_layer = Conv1D(filters=4, kernel_size=5, activation='relu',padding='same', name=f'CNN_LAYER_1')(temporal_input)\n",
    "    cnn_layer = MaxPooling1D(pool_size=3)(cnn_layer)\n",
    "    cnn_layer = Conv1D(filters=8, kernel_size=3, activation='relu',padding='same', name=f'CNN_LAYER_2')(cnn_layer)\n",
    "    cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "    cnn_layer = Flatten(name='FLATTEN')(cnn_layer)\n",
    "    CNN_combined = Concatenate(axis=1, name='CONCAT')([cnn_layer, static_input])\n",
    "    output = Dense(1, activation='sigmoid', name='cnn_OUTPUT_LAYER')(CNN_combined)\n",
    "    model = Model(inputs=[temporal_input, static_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "temporal_input = Input(shape=(num_time_steps, num_features),name = 'TEMPORAL_INPUT')\n",
    "static_input = Input(shape=(X_train_static.shape[1]),name = 'STATIC_INPUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training and evaluating on test set for optimized configurations (concat - dense)\n",
    "\n",
    "def concat_dense_evaluation(X_train_temporal,X_train_static, y_train, X_test_temporal,\n",
    "                            X_test_static, y_test, batch_size, optimizer, initial_learning_rate, model):\n",
    "    \n",
    "    decay_rate = 0.1  # Decay rate\n",
    "    decay_steps = 20  # Decay steps (number of steps before applying decay)\n",
    "    epochs = 50\n",
    "\n",
    "    def learning_rate_scheduler(epoch):\n",
    "        return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "    \n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=initial_learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([X_train_temporal, X_train_static], y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=([X_test_temporal, X_test_static], y_test),\n",
    "                        shuffle=False,callbacks = [lr_scheduler])\n",
    "\n",
    "    # Plot the loss on train vs validate tests\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate on the testing set\n",
    "    y_pred_probs = model.predict([X_test_temporal, X_test_static])\n",
    "    y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    test_accuracy =  accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 =  f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    y_train_pred_probs = model.predict([X_train_temporal, X_train_static])\n",
    "    y_train_pred = (y_train_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "   \n",
    "    print(f\"Testing Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % test_accuracy)\n",
    "    print(\"Precision: %.3f\" % test_precision)\n",
    "    print(\"Recall: %.3f\" % test_recall)\n",
    "    print(\"F1 score: %.3f\" % test_f1)\n",
    "  \n",
    "    print('-----------------------------------')\n",
    "    print(f\"Training Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % train_accuracy)\n",
    "    print(\"Precision: %.3f\" % train_precision)\n",
    "    print(\"Recall: %.3f\" % train_recall)\n",
    "    print(\"F1 score: %.3f\" % train_f1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training and evaluating on test set for optimized configurations (concat - ML)\n",
    "\n",
    "def concat_ML_evaluation(X_train_temporal,X_train_static, y_train, X_test_temporal, \n",
    "                         X_test_static, y_test, batch_size, optimizer, initial_learning_rate, model, ml_model):\n",
    "    \n",
    "    decay_rate = 0.1  # Decay rate\n",
    "    decay_steps = 20  # Decay steps (number of steps before applying decay)\n",
    "    epochs = 50\n",
    "\n",
    "    def learning_rate_scheduler(epoch):\n",
    "        return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "    \n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=initial_learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([X_train_temporal, X_train_static], y_train,\n",
    "                                                            epochs=epochs, batch_size=batch_size,\n",
    "                                                            validation_data=([X_test_temporal, X_test_static], y_test),\n",
    "                                                            shuffle=False, callbacks=[lr_scheduler])\n",
    "\n",
    "    # Plot the loss on train vs validate tests\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    preds,preds_train = classifier_prediction(X_train_temporal,X_test_temporal,X_train_static, \n",
    "                                              X_test_static,y_train,y_test, model = ml_model, \n",
    "                                              feature_extractor_model = model, layer_name='CONCAT')\n",
    "    \n",
    "    \n",
    "    # Evaluate on the testing set\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "    test_precision = precision_score(y_test, preds)\n",
    "    test_recall = recall_score(y_test, preds)\n",
    "    test_f1 =  f1_score(y_test, preds)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    train_accuracy = accuracy_score(y_train, preds_train)\n",
    "    train_precision = precision_score(y_train, preds_train)\n",
    "    train_recall = recall_score(y_train, preds_train)\n",
    "    train_f1 = f1_score(y_train, preds_train)\n",
    "   \n",
    "    print(f\"Testing Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % test_accuracy)\n",
    "    print(\"Precision: %.3f\" % test_precision)\n",
    "    print(\"Recall: %.3f\" % test_recall)\n",
    "    print(\"F1 score: %.3f\" % test_f1)\n",
    "  \n",
    "    print('-----------------------------------')\n",
    "    print(f\"Training Set Performance\")\n",
    "    print(\"Accuracy: %.3f\" % train_accuracy)\n",
    "    print(\"Precision: %.3f\" % train_precision)\n",
    "    print(\"Recall: %.3f\" % train_recall)\n",
    "    print(\"F1 score: %.3f\" % train_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Concat (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dense_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static, \n",
    "                        y_test_preprocessed, batch_size=64, optimizer='adam',\n",
    "                        initial_learning_rate=0.0001, model=RNN_Concat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Concat (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dense_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                        y_test_preprocessed, batch_size=64, optimizer='adam', \n",
    "                        initial_learning_rate=0.0001, model=LSTM_Concat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Concat (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dense_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                        y_test_preprocessed, batch_size=64, optimizer='adam', \n",
    "                        initial_learning_rate=0.001, model=CNN_Concat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Concat + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                     y_test_preprocessed, batch_size=128, optimizer='adam',\n",
    "                     initial_learning_rate=0.0001, model=RNN_Concat_LR(), ml_model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal,\n",
    "                     X_test_static, y_test_preprocessed, batch_size=32, optimizer='rmsprop', \n",
    "                     initial_learning_rate=0.0001, model=RNN_Concat_RF(), ml_model=RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal,\n",
    "                     X_test_static, y_test_preprocessed, batch_size=128, optimizer='adam',\n",
    "                     initial_learning_rate=0.0001, model=RNN_Concat_XGB(), ml_model=XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Concat + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                     y_test_preprocessed, batch_size=64, optimizer='adam', \n",
    "                     initial_learning_rate=0.0001, model=LSTM_Concat_LR(), ml_model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal,\n",
    "                     X_test_static, y_test_preprocessed, batch_size=64, optimizer='adam',\n",
    "                     initial_learning_rate=0.001, model=LSTM_Concat_RF(), ml_model=RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal,\n",
    "                     X_test_static, y_test_preprocessed, batch_size=64, optimizer='adam',\n",
    "                     initial_learning_rate=0.0001, model=LSTM_Concat_XGB(), ml_model=XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Concat + ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                     y_test_preprocessed, batch_size=32, optimizer='adam', \n",
    "                     initial_learning_rate=0.001, model=CNN_Concat_LR(), ml_model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                     y_test_preprocessed, batch_size=64, optimizer='adam', \n",
    "                     initial_learning_rate=0.001, model=CNN_Concat_RF(), ml_model=RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ML_evaluation(X_train_temporal,X_train_static, y_train_preprocessed, X_test_temporal, X_test_static,\n",
    "                     y_test_preprocessed, batch_size=64, optimizer='adam', \n",
    "                     initial_learning_rate=0.001, model=CNN_Concat_XGB(), ml_model=XGBClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
